---
phase: 04-nl-mapping-engine
plan: 05
type: execute
wave: 3
depends_on: ["04-03", "04-04"]
files_modified:
  - src/orchestrator/nl_engine/self_correction.py
  - src/orchestrator/models/correction.py
  - tests/orchestrator/test_self_correction.py
autonomous: true

must_haves:
  truths:
    - "When template validation fails, system automatically attempts to fix the template"
    - "Self-correction loop has maximum 3 attempts per CONTEXT.md"
    - "After 3 failures, user is prompted with options to proceed"
  artifacts:
    - path: "src/orchestrator/nl_engine/self_correction.py"
      provides: "self_correction_loop, CorrectionAttempt tracking"
      exports: ["self_correction_loop", "MaxCorrectionsExceeded"]
    - path: "src/orchestrator/models/correction.py"
      provides: "CorrectionAttempt, CorrectionResult Pydantic models"
      exports: ["CorrectionAttempt", "CorrectionResult", "CorrectionOptions"]
  key_links:
    - from: "self_correction.py"
      to: "template_validator.py"
      via: "validation in loop"
      pattern: "validate_template_output"
    - from: "self_correction.py"
      to: "anthropic API"
      via: "LLM-based template fixing"
      pattern: "client\\.(messages\\.create|beta\\.messages)"
---

<objective>
Implement the self-correction loop that automatically fixes template validation errors.

Purpose: When a generated Jinja2 mapping template produces output that fails UPS schema validation, automatically attempt to fix the template by providing validation errors to the LLM, up to 3 times per CONTEXT.md Decision 4.

Output: Self-correction loop with attempt tracking, clear user feedback, and escalation options after max retries.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-nl-mapping-engine/04-CONTEXT.md
@.planning/phases/04-nl-mapping-engine/04-RESEARCH.md
@.planning/phases/04-nl-mapping-engine/04-03-SUMMARY.md
@.planning/phases/04-nl-mapping-engine/04-04-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create correction models and tracking</name>
  <files>
    - src/orchestrator/models/correction.py
    - src/orchestrator/models/__init__.py
  </files>
  <action>
Create models for tracking self-correction attempts and results.

**In correction.py, create:**

1. `CorrectionAttempt` - Pydantic model for single attempt:
   - attempt_number: int  # 1, 2, or 3
   - original_template: str  # Template before correction
   - validation_errors: list[ValidationError]  # Errors from validation
   - corrected_template: Optional[str] = None  # Template after correction
   - changes_made: list[str] = []  # Description of changes
   - success: bool = False  # Did this attempt pass validation?
   - timestamp: datetime  # When attempt was made

2. `CorrectionResult` - Pydantic model for overall result:
   - final_template: Optional[str] = None  # Working template if successful
   - attempts: list[CorrectionAttempt] = []
   - success: bool = False
   - total_attempts: int = 0
   - failure_reason: Optional[str] = None  # If max attempts reached

3. `CorrectionOptions` - Enum for user choices after max retries:
   - CORRECT_SOURCE = "correct_source"  # User fixes source data
   - MANUAL_FIX = "manual_fix"  # User provides manual template fix
   - SKIP_PROBLEMATIC = "skip_problematic"  # Skip failing rows
   - ABORT = "abort"  # Abort operation

4. `MaxCorrectionsExceeded` - Exception:
   - result: CorrectionResult
   - options: list[CorrectionOptions] = [CorrectionOptions.CORRECT_SOURCE, ...]

**Export from models/__init__.py.**
  </action>
  <verify>
```bash
python -c "
from src.orchestrator.models.correction import CorrectionAttempt, CorrectionResult, CorrectionOptions, MaxCorrectionsExceeded
print(f'Options: {[o.value for o in CorrectionOptions]}')
"
```
  </verify>
  <done>CorrectionAttempt, CorrectionResult, CorrectionOptions models exist; MaxCorrectionsExceeded exception defined with user options</done>
</task>

<task type="auto">
  <name>Task 2: Implement self-correction loop</name>
  <files>
    - src/orchestrator/nl_engine/self_correction.py
    - src/orchestrator/nl_engine/__init__.py
  </files>
  <action>
Create self_correction.py that implements the validation-fix-retry loop.

**Implement:**

1. `format_errors_for_llm(errors: list[ValidationError]) -> str`:
   - Format errors for LLM consumption:
     ```
     Field: ShipTo.Phone.Number
     Expected: string with 10-15 digits
     Got: "555-1234" (too short)
     Fix: Ensure phone numbers include area code

     Field: ShipTo.Address.PostalCode
     Expected: string matching ZIP format
     Got: null
     Fix: Map a source column to PostalCode or provide default
     ```
   - Include actionable fix suggestions

2. `extract_template_from_response(response_text: str) -> str`:
   - Extract Jinja2 template from LLM response
   - Look for ```jinja2 or ``` code blocks
   - Strip markdown formatting
   - Return clean template string

3. `attempt_correction(template: str, errors: list[ValidationError], source_schema: list[ColumnInfo]) -> CorrectionAttempt`:
   - Call Claude API with:
     - model: "claude-sonnet-4-5"
     - System prompt: "You fix Jinja2 template validation errors. Only change what's needed."
     - User message: Original template + formatted errors + source schema context
   - Extract corrected template from response
   - Describe changes made
   - Return CorrectionAttempt (success determined by caller)

4. `self_correction_loop(template: str, source_schema: list[ColumnInfo], target_schema: dict | None = None, max_attempts: int = 3) -> CorrectionResult`:
   - Per CONTEXT.md Decision 4:
     - Default max_attempts = 3
     - Each attempt: render template with sample data, validate output
     - If valid: return success with working template
     - If invalid: attempt correction, log attempt
   - Track all attempts in CorrectionResult
   - After max_attempts: raise MaxCorrectionsExceeded with all attempts
   - User feedback format per CONTEXT.md:
     ```
     Template validation failed (attempt 2 of 3)
     Error: Field 'ShipTo.Phone.Number' invalid format
     Expected: 10-digit US phone number
     Got: "555-1234" (missing area code)
     Attempting correction...
     ```

5. `format_user_feedback(attempt: CorrectionAttempt, max_attempts: int) -> str`:
   - Format current attempt status for user display
   - Include attempt number, errors, and status

**Configuration:**
- max_attempts: Configurable (1-5, default 3)
- auto_confirm_fixes: bool (default False per CONTEXT.md)

**Export from nl_engine/__init__.py:**
- self_correction_loop
- MaxCorrectionsExceeded
- format_user_feedback
  </action>
  <verify>
```bash
python -c "
from src.orchestrator.nl_engine.self_correction import format_errors_for_llm, extract_template_from_response
from src.orchestrator.nl_engine.template_validator import ValidationError

# Test error formatting
errors = [
    ValidationError(path='ShipTo.Name', message='Too long', expected='max 35 chars', actual='A'*40, schema_rule='maxLength')
]
formatted = format_errors_for_llm(errors)
print('Error formatted:', 'ShipTo.Name' in formatted)

# Test template extraction
response = '''Here is the fixed template:
\`\`\`jinja2
{{ name | truncate_address(35) }}
\`\`\`
'''
template = extract_template_from_response(response)
print('Template extracted:', 'truncate_address' in template)
"
```
  </verify>
  <done>self_correction_loop implements 3-attempt retry with clear user feedback; MaxCorrectionsExceeded raised with user options after max retries</done>
</task>

<task type="auto">
  <name>Task 3: Add tests for self-correction</name>
  <files>
    - tests/orchestrator/test_self_correction.py
  </files>
  <action>
Create comprehensive tests for self-correction functionality.

**Test cases:**

1. `TestCorrectionModels`:
   - test_correction_attempt_minimal
   - test_correction_attempt_with_changes
   - test_correction_result_success
   - test_correction_result_failure
   - test_correction_options_values

2. `TestFormatErrorsForLLM`:
   - test_single_error_format
   - test_multiple_errors_format
   - test_includes_fix_suggestions
   - test_nested_path_format

3. `TestExtractTemplate`:
   - test_extract_from_jinja2_block
   - test_extract_from_plain_block
   - test_extract_strips_markdown
   - test_handles_no_block -> returns full response

4. `TestAttemptCorrection` (integration, skip without API):
   - test_correction_modifies_template
   - test_correction_addresses_errors

5. `TestSelfCorrectionLoop` (integration, skip without API):
   - test_loop_succeeds_on_valid_template
   - test_loop_retries_on_invalid
   - test_loop_raises_after_max_attempts
   - test_loop_tracks_all_attempts

6. `TestMaxCorrectionsExceeded`:
   - test_exception_contains_result
   - test_exception_contains_options
   - test_all_options_available

7. `TestUserFeedback`:
   - test_format_includes_attempt_number
   - test_format_includes_errors
   - test_format_includes_status

**Fixtures:**
- sample_template: Simple Jinja2 template
- validation_errors: List of sample ValidationError
- sample_source_schema: list[ColumnInfo]

Use mocking for Claude API calls in unit tests.
  </action>
  <verify>
```bash
cd /Users/matthewhans/Desktop/Programming/ShipAgent && python -m pytest tests/orchestrator/test_self_correction.py -v -k "not Integration"
```
  </verify>
  <done>Unit tests pass for error formatting, template extraction, and models; integration tests skip without API key</done>
</task>

</tasks>

<verification>
1. `python -c "from src.orchestrator.nl_engine.self_correction import self_correction_loop"` succeeds
2. `python -c "from src.orchestrator.models.correction import CorrectionOptions"` succeeds
3. `pytest tests/orchestrator/test_self_correction.py -v -k "not Integration"` passes
4. MaxCorrectionsExceeded includes all 4 options from CONTEXT.md Decision 4
5. User feedback format matches CONTEXT.md examples
</verification>

<success_criteria>
1. CorrectionAttempt tracks each correction attempt with changes made
2. self_correction_loop retries up to max_attempts (default 3)
3. MaxCorrectionsExceeded raised after max failures with 4 user options
4. format_errors_for_llm produces actionable error descriptions
5. extract_template_from_response handles markdown code blocks
6. Unit tests pass (15+ tests)
</success_criteria>

<output>
After completion, create `.planning/phases/04-nl-mapping-engine/04-05-SUMMARY.md`
</output>
