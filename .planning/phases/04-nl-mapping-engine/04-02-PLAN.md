---
phase: 04-nl-mapping-engine
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - src/orchestrator/models/filter.py
  - src/orchestrator/nl_engine/filter_generator.py
  - tests/orchestrator/test_filter_generator.py
autonomous: true

must_haves:
  truths:
    - "Natural language filter 'California orders' produces SQL WHERE clause 'state = \"CA\"'"
    - "Filter 'today's orders' produces date comparison using current system date"
    - "Ambiguous filters (multiple date columns) set needs_clarification=True"
  artifacts:
    - path: "src/orchestrator/models/filter.py"
      provides: "SQLFilterResult, ColumnInfo Pydantic models"
      exports: ["SQLFilterResult", "ColumnInfo"]
    - path: "src/orchestrator/nl_engine/filter_generator.py"
      provides: "generate_filter function with schema grounding"
      exports: ["generate_filter", "FilterGenerationError"]
  key_links:
    - from: "filter_generator.py"
      to: "sqlglot.parse"
      via: "SQL syntax validation"
      pattern: "sqlglot\\.parse"
    - from: "filter_generator.py"
      to: "anthropic structured outputs"
      via: "schema-grounded generation"
      pattern: "client\\.beta\\.messages\\.parse"
---

<objective>
Create schema-grounded SQL filter generation from natural language expressions.

Purpose: Enable users to filter shipment data using natural language ("California orders", "today's orders", "over 5 lbs") with the filter converted to validated SQL WHERE clauses that reference only actual columns in the source data.

Output: Filter models and a generator that produces SQL WHERE clauses with schema grounding to prevent column hallucination.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-nl-mapping-engine/04-CONTEXT.md
@.planning/phases/04-nl-mapping-engine/04-RESEARCH.md
@src/mcp/data_source/models.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create filter models with column info</name>
  <files>
    - src/orchestrator/models/filter.py
    - src/orchestrator/models/__init__.py
  </files>
  <action>
Create filter models for SQL generation results.

**Add to pyproject.toml dependencies:**
- sqlglot>=26.0.0

**In filter.py, create:**

1. `ColumnInfo` - Pydantic model for schema column info:
   - name: str
   - type: str  # "string", "integer", "float", "date", "boolean"
   - nullable: bool = True
   - sample_values: list[Any] = []  # Optional sample for context

2. `SQLFilterResult` - Pydantic model for generated filter:
   - where_clause: str  # SQL WHERE clause without "WHERE" keyword
   - columns_used: list[str]  # Column names referenced in the filter
   - date_column: Optional[str] = None  # Date column used for temporal filters
   - needs_clarification: bool = False  # True if ambiguous
   - clarification_questions: list[str] = []  # Questions to ask user
   - original_expression: str  # Original NL filter

3. `FilterGenerationError` - Custom exception:
   - message: str
   - original_expression: str
   - available_columns: list[str]

**Update models/__init__.py to export all filter models.**
  </action>
  <verify>
```bash
python -c "from src.orchestrator.models.filter import SQLFilterResult, ColumnInfo; print('Filter models imported')"
```
  </verify>
  <done>SQLFilterResult and ColumnInfo models exist with all fields; FilterGenerationError exception defined</done>
</task>

<task type="auto">
  <name>Task 2: Implement schema-grounded filter generator</name>
  <files>
    - src/orchestrator/nl_engine/filter_generator.py
    - src/orchestrator/nl_engine/__init__.py
  </files>
  <action>
Create filter_generator.py that generates SQL WHERE clauses with schema grounding.

**Dependencies:** Ensure `sqlglot>=26.0.0` in pyproject.toml.

**Implement:**

1. `validate_sql_syntax(where_clause: str) -> bool`:
   - Use sqlglot.parse() to validate SQL syntax
   - Wrap in SELECT * FROM t WHERE {clause} for validation
   - Return True if valid, raise ValueError if invalid

2. `generate_filter(filter_expression: str, schema: list[ColumnInfo], system_timezone: str = "America/Los_Angeles") -> SQLFilterResult`:
   - Build column context string from schema (name + type for each column)
   - Identify date columns and numeric columns from schema
   - Use Claude structured outputs with:
     - model: "claude-sonnet-4-5"
     - betas: ["structured-outputs-2025-11-13"]
     - output_format: SQLFilterResult
   - System prompt MUST include:
     - Current date (datetime.now().strftime('%Y-%m-%d'))
     - System timezone
     - CRITICAL: "ONLY use column names from the provided schema"
     - Date column list for temporal filters
     - Numeric column list for comparisons
     - Instructions to set needs_clarification=True for ambiguous cases
   - After generation:
     - Validate SQL syntax with validate_sql_syntax()
     - Verify all columns_used exist in schema
     - Raise FilterGenerationError if validation fails
   - Return SQLFilterResult

3. Per CONTEXT.md Decision 3:
   - If multiple date columns and filter is temporal, set needs_clarification=True
   - Add clarification question: "Which date column? {date_columns}"
   - If ambiguous numeric comparison, set needs_clarification=True
   - Add clarification question: "Which column for comparison? {numeric_columns}"

**Ambiguity detection heuristics:**
- Temporal filter + multiple date columns -> clarify
- "over X" + multiple numeric columns with similar names -> clarify
- "big" / "large" without clear definition -> clarify

**Export from nl_engine/__init__.py:**
- generate_filter
- validate_sql_syntax
- FilterGenerationError
  </action>
  <verify>
```bash
python -c "
from src.orchestrator.nl_engine.filter_generator import generate_filter, validate_sql_syntax
# Test SQL validation (doesn't need API)
assert validate_sql_syntax('state = \"CA\"') == True
print('SQL validation works')
"
```
  </verify>
  <done>generate_filter function exists with schema grounding, validate_sql_syntax uses sqlglot, ambiguity detection implemented per CONTEXT.md</done>
</task>

<task type="auto">
  <name>Task 3: Add unit tests for filter generation</name>
  <files>
    - tests/orchestrator/test_filter_generator.py
  </files>
  <action>
Create comprehensive unit tests for filter generation.

**Test cases:**

1. `TestSQLValidation`:
   - test_valid_simple_equality -> "state = 'CA'" passes
   - test_valid_date_comparison -> "order_date = '2026-01-25'" passes
   - test_valid_numeric_comparison -> "weight > 5" passes
   - test_valid_compound_filter -> "state = 'CA' AND weight > 5" passes
   - test_invalid_syntax_missing_value -> "state = " raises ValueError
   - test_invalid_syntax_bad_operator -> "state >< 'CA'" raises ValueError

2. `TestColumnInfo`:
   - test_minimal_column -> name and type only
   - test_column_with_samples -> includes sample_values

3. `TestSQLFilterResult`:
   - test_simple_result -> where_clause populated
   - test_result_with_clarification -> needs_clarification=True with questions
   - test_columns_used_populated -> columns_used matches filter

4. `TestFilterGeneratorIntegration` (skip without API key):
   - test_state_filter -> "California orders" with state column
   - test_date_filter -> "today's orders" with single date column
   - test_numeric_filter -> "over 5 lbs" with weight column
   - test_ambiguous_date_columns -> Multiple date columns triggers clarification
   - test_compound_filter -> "California orders over 5 lbs"

**Test fixtures:**
- sample_schema: list[ColumnInfo] with typical shipping columns
- shipping_schema: More complex schema with multiple date/weight columns

Use @pytest.mark.integration for API tests, skip if ANTHROPIC_API_KEY not set.
  </action>
  <verify>
```bash
cd /Users/matthewhans/Desktop/Programming/ShipAgent && python -m pytest tests/orchestrator/test_filter_generator.py -v -k "not Integration"
```
  </verify>
  <done>Unit tests pass for SQL validation and model construction; integration tests skip gracefully</done>
</task>

</tasks>

<verification>
1. `python -c "from src.orchestrator.models.filter import SQLFilterResult"` succeeds
2. `python -c "from src.orchestrator.nl_engine.filter_generator import generate_filter"` succeeds
3. `pytest tests/orchestrator/test_filter_generator.py -v -k "not Integration"` passes
4. validate_sql_syntax correctly validates/rejects SQL using sqlglot
</verification>

<success_criteria>
1. SQLFilterResult model captures WHERE clause, columns used, and clarification flags
2. generate_filter accepts schema as list[ColumnInfo] for grounding
3. validate_sql_syntax uses sqlglot for SQL syntax validation
4. Ambiguous filters set needs_clarification=True per CONTEXT.md Decision 3
5. Unit tests pass (10+ tests covering validation, models, and edge cases)
</success_criteria>

<output>
After completion, create `.planning/phases/04-nl-mapping-engine/04-02-SUMMARY.md`
</output>
