---
phase: 04-nl-mapping-engine
plan: 07
type: execute
wave: 4
depends_on: ["04-01", "04-02", "04-03", "04-04", "04-05", "04-06"]
files_modified:
  - src/orchestrator/nl_engine/engine.py
  - tests/orchestrator/test_integration.py
  - tests/orchestrator/conftest.py
autonomous: false

must_haves:
  truths:
    - "End-to-end: 'Ship California orders via Ground' produces validated UPS payload"
    - "All 6 NL requirements (NL-01 through NL-06) demonstrated working"
    - "Human verification confirms natural language workflow functions correctly"
  artifacts:
    - path: "src/orchestrator/nl_engine/engine.py"
      provides: "NLMappingEngine orchestrating all components"
      exports: ["NLMappingEngine", "process_command"]
    - path: "tests/orchestrator/test_integration.py"
      provides: "Integration tests covering all requirements"
      min_tests: 10
  key_links:
    - from: "engine.py"
      to: "intent_parser.py"
      via: "parse_intent call"
      pattern: "parse_intent"
    - from: "engine.py"
      to: "filter_generator.py"
      via: "generate_filter call"
      pattern: "generate_filter"
    - from: "engine.py"
      to: "mapping_generator.py"
      via: "generate_mapping_template call"
      pattern: "generate_mapping_template"
    - from: "engine.py"
      to: "template_validator.py"
      via: "validation call"
      pattern: "validate_template_output"
    - from: "engine.py"
      to: "self_correction.py"
      via: "correction loop"
      pattern: "self_correction_loop"
---

<objective>
Create the unified NL Mapping Engine and integration tests covering all 6 requirements.

Purpose: Combine all Phase 4 components into a cohesive engine that processes natural language shipping commands end-to-end, and verify all NL requirements are satisfied.

Output: NLMappingEngine class orchestrating all components, comprehensive integration tests, and human verification of the complete workflow.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-nl-mapping-engine/04-CONTEXT.md
@.planning/phases/04-nl-mapping-engine/04-RESEARCH.md
@.planning/phases/04-nl-mapping-engine/04-01-SUMMARY.md
@.planning/phases/04-nl-mapping-engine/04-02-SUMMARY.md
@.planning/phases/04-nl-mapping-engine/04-03-SUMMARY.md
@.planning/phases/04-nl-mapping-engine/04-04-SUMMARY.md
@.planning/phases/04-nl-mapping-engine/04-05-SUMMARY.md
@.planning/phases/04-nl-mapping-engine/04-06-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create unified NLMappingEngine</name>
  <files>
    - src/orchestrator/nl_engine/engine.py
    - src/orchestrator/nl_engine/__init__.py
    - src/orchestrator/__init__.py
  </files>
  <action>
Create the unified NLMappingEngine class that orchestrates all Phase 4 components.

**In engine.py, implement:**

1. `NLMappingEngine` class:
   ```python
   class NLMappingEngine:
       """Unified natural language to UPS mapping engine.

       Orchestrates intent parsing, filter generation, template mapping,
       validation, self-correction, and elicitation.
       """

       def __init__(self, max_correction_attempts: int = 3):
           self.max_correction_attempts = max_correction_attempts
           self._jinja_env = get_logistics_environment()

       async def process_command(
           self,
           command: str,
           source_schema: list[ColumnInfo],
           example_row: dict | None = None,
           user_mappings: list[FieldMapping] | None = None
       ) -> CommandResult:
           """Process a natural language shipping command.

           Returns CommandResult with:
           - intent: Parsed ShippingIntent
           - filter_result: Generated SQL filter (if applicable)
           - mapping_template: Generated Jinja2 template
           - validation_result: Validation outcome
           - needs_elicitation: List of questions if clarification needed
           """
           ...
   ```

2. `CommandResult` - Pydantic model for processing outcome:
   - command: str  # Original command
   - intent: ShippingIntent
   - filter_result: Optional[SQLFilterResult] = None
   - sql_where: Optional[str] = None  # Final SQL WHERE clause
   - mapping_template: Optional[MappingTemplate] = None
   - validation_result: Optional[ValidationResult] = None
   - corrections_made: list[CorrectionAttempt] = []
   - needs_elicitation: list[ElicitationQuestion] = []
   - success: bool = False
   - error: Optional[str] = None

3. Processing flow in `process_command`:
   ```
   1. Parse intent from command (intent_parser.parse_intent)
   2. Check if elicitation needed (needs_elicitation)
      - If yes: Return with needs_elicitation populated
   3. Generate SQL filter if filter_criteria present (filter_generator.generate_filter)
      - If needs_clarification: Add to needs_elicitation
   4. Generate mapping template (mapping_generator)
      - If no user_mappings: Suggest mappings, require confirmation
   5. Render template with example_row
   6. Validate output (template_validator.validate_template_output)
      - If invalid: Run self_correction_loop
   7. Return CommandResult with all artifacts
   ```

4. `render_with_validation(template: MappingTemplate, row_data: dict) -> tuple[dict, ValidationResult]`:
   - Render template with row data
   - Validate output
   - Return both rendered dict and validation result

5. Helper methods:
   - `_check_elicitation_needed(intent, filter_result)` -> list[ElicitationQuestion]
   - `_apply_elicitation_responses(responses: dict)` -> Update internal state

**Update nl_engine/__init__.py:**
- Export NLMappingEngine, CommandResult, process_command

**Update orchestrator/__init__.py:**
- Export main public API:
  - NLMappingEngine
  - ShippingIntent, FilterCriteria, RowQualifier
  - MappingTemplate, FieldMapping
  - ValidationResult
  - ElicitationQuestion, ElicitationResponse
  </action>
  <verify>
```bash
python -c "
from src.orchestrator import NLMappingEngine
from src.orchestrator.models.filter import ColumnInfo

engine = NLMappingEngine()
print('NLMappingEngine instantiated successfully')
print(f'Max correction attempts: {engine.max_correction_attempts}')
"
```
  </verify>
  <done>NLMappingEngine class created with process_command method; orchestrator package exports all main types</done>
</task>

<task type="auto">
  <name>Task 2: Create integration tests for all requirements</name>
  <files>
    - tests/orchestrator/test_integration.py
    - tests/orchestrator/conftest.py
  </files>
  <action>
Create comprehensive integration tests verifying all 6 NL requirements.

**In conftest.py, create fixtures:**

```python
@pytest.fixture
def sample_shipping_schema():
    """Schema for typical shipping data."""
    return [
        ColumnInfo(name="customer_name", type="string"),
        ColumnInfo(name="address_line1", type="string"),
        ColumnInfo(name="city", type="string"),
        ColumnInfo(name="state", type="string"),
        ColumnInfo(name="zip", type="string"),
        ColumnInfo(name="phone", type="string"),
        ColumnInfo(name="weight_lbs", type="float"),
        ColumnInfo(name="order_date", type="date"),
    ]

@pytest.fixture
def sample_row_data():
    """Sample row for template rendering."""
    return {
        "customer_name": "John Smith",
        "address_line1": "123 Main Street",
        "city": "Los Angeles",
        "state": "CA",
        "zip": "90001",
        "phone": "5551234567",
        "weight_lbs": 2.5,
        "order_date": "2026-01-25",
    }

@pytest.fixture
def sample_mappings():
    """User-confirmed mappings."""
    return [
        FieldMapping(source_column="customer_name", target_path="ShipTo.Name"),
        FieldMapping(source_column="address_line1", target_path="ShipTo.Address.AddressLine", transformation="[value]"),
        FieldMapping(source_column="city", target_path="ShipTo.Address.City"),
        FieldMapping(source_column="state", target_path="ShipTo.Address.StateProvinceCode"),
        FieldMapping(source_column="zip", target_path="ShipTo.Address.PostalCode"),
        FieldMapping(source_column="phone", target_path="ShipTo.Phone.Number"),
    ]
```

**In test_integration.py, create requirement tests:**

Mark all as @pytest.mark.integration, skip without ANTHROPIC_API_KEY.

1. `TestNL01_NaturalLanguageCommands`:
   - test_ship_california_orders_ground
   - test_ship_all_orders_overnight
   - test_ship_first_ten_orders
   - Verifies: "User can issue natural language commands"

2. `TestNL02_IntentParsing`:
   - test_extracts_data_source
   - test_extracts_filter_criteria
   - test_extracts_service_code
   - test_extracts_package_defaults
   - Verifies: "System parses intent to extract data source, filter, service, package"

3. `TestNL03_TemplatGeneration`:
   - test_generates_jinja2_template
   - test_template_maps_columns_to_ups_fields
   - test_template_includes_transformations
   - Verifies: "System generates Jinja2 mapping templates"

4. `TestNL04_SchemaValidation`:
   - test_validates_against_ups_schema
   - test_reports_missing_required_fields
   - test_reports_type_mismatches
   - Verifies: "System validates templates against UPS schema"

5. `TestNL05_SelfCorrection`:
   - test_corrects_template_on_validation_failure
   - test_respects_max_attempts
   - test_raises_after_max_failures
   - Verifies: "System self-corrects when validation fails"

6. `TestNL06_NaturalLanguageFilters`:
   - test_california_filter -> WHERE state = 'CA'
   - test_today_filter -> WHERE order_date = '2026-01-25'
   - test_weight_filter -> WHERE weight_lbs > 5
   - test_compound_filter -> state + weight
   - Verifies: "User can filter using natural language"

7. `TestEndToEnd`:
   - test_full_workflow -> Command to validated UPS payload
   - test_with_elicitation -> Ambiguous command triggers questions
   - test_with_self_correction -> Invalid template gets fixed

**Test verification commands:**
- Each test should verify specific artifacts (SQL clause, template string, validation result)
- Use assertions that map directly to success criteria in ROADMAP.md
  </action>
  <verify>
```bash
cd /Users/matthewhans/Desktop/Programming/ShipAgent && python -m pytest tests/orchestrator/test_integration.py -v --collect-only | grep "test_" | wc -l
# Should show 15+ tests collected
```
  </verify>
  <done>Integration tests created covering all 6 NL requirements; tests skip gracefully without API key</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
Complete Natural Language and Mapping Engine with:
- Intent parsing (NL-01, NL-02)
- SQL filter generation (NL-06)
- Jinja2 template generation (NL-03)
- UPS schema validation (NL-04)
- Self-correction loop (NL-05)
- Elicitation for ambiguous commands
  </what-built>
  <how-to-verify>
1. **Run unit tests** (no API key required):
   ```bash
   cd /Users/matthewhans/Desktop/Programming/ShipAgent
   python -m pytest tests/orchestrator/ -v -k "not Integration"
   ```
   Expected: All unit tests pass

2. **Verify package exports**:
   ```bash
   python -c "
   from src.orchestrator import (
       NLMappingEngine,
       ShippingIntent, FilterCriteria, RowQualifier,
       MappingTemplate, FieldMapping,
       ValidationResult,
       ElicitationQuestion, ElicitationResponse
   )
   print('All exports available')
   "
   ```
   Expected: Imports succeed without error

3. **Test logistics filters**:
   ```bash
   python -c "
   from src.orchestrator.filters.logistics import (
       truncate_address, format_us_zip, convert_weight, to_ups_phone
   )
   print('truncate:', truncate_address('123 Main Street Suite 400', 20))
   print('zip:', format_us_zip('900011234'))
   print('weight:', convert_weight(5, 'kg', 'lbs'))
   print('phone:', to_ups_phone('(555) 123-4567'))
   "
   ```
   Expected:
   - truncate: "123 Main Street"
   - zip: "90001-1234"
   - weight: ~11.02 (5 * 2.20462)
   - phone: "5551234567"

4. **Test SQL validation**:
   ```bash
   python -c "
   from src.orchestrator.nl_engine.filter_generator import validate_sql_syntax
   print('Valid SQL:', validate_sql_syntax('state = \"CA\"'))
   "
   ```
   Expected: True

5. **Optional: Run integration tests** (requires ANTHROPIC_API_KEY):
   ```bash
   export ANTHROPIC_API_KEY="your-key"
   python -m pytest tests/orchestrator/test_integration.py -v -k "NL01"
   ```

6. **Verify test count**:
   ```bash
   python -m pytest tests/orchestrator/ --collect-only | grep "test session starts" -A 5
   ```
   Expected: 50+ tests collected across all test files
  </how-to-verify>
  <resume-signal>Type "approved" if all verifications pass, or describe any issues found</resume-signal>
</task>

</tasks>

<verification>
1. `pytest tests/orchestrator/ -v -k "not Integration"` passes (all unit tests)
2. `python -c "from src.orchestrator import NLMappingEngine"` succeeds
3. All 6 NL requirements have corresponding integration tests
4. Human verification confirms filters, validation, and engine work correctly
</verification>

<success_criteria>
1. NLMappingEngine orchestrates all Phase 4 components
2. process_command returns CommandResult with all artifacts
3. Integration tests cover all 6 NL requirements (NL-01 through NL-06)
4. Unit tests pass without API key (50+ tests)
5. Integration tests skip gracefully without API key
6. Human verification confirms end-to-end workflow
</success_criteria>

<output>
After completion, create `.planning/phases/04-nl-mapping-engine/04-07-SUMMARY.md`
</output>
