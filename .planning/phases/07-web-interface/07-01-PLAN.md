---
phase: 07-web-interface
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/api/routes/commands.py
  - src/api/routes/labels.py
  - src/api/routes/progress.py
  - src/api/schemas.py
  - src/api/main.py
  - src/orchestrator/batch/sse_observer.py
  - requirements.txt
autonomous: true

must_haves:
  truths:
    - "User can submit NL commands via POST /api/v1/commands"
    - "User can retrieve command history via GET /api/v1/commands/history"
    - "User can download individual labels via GET /api/v1/labels/{tracking}"
    - "User can download all labels as ZIP via GET /api/v1/jobs/{id}/labels/zip"
    - "SSE observer bridges batch events to client connections"
  artifacts:
    - path: "src/api/routes/commands.py"
      provides: "Command submission and history endpoints"
      exports: ["router"]
    - path: "src/api/routes/labels.py"
      provides: "Label download and ZIP endpoints"
      exports: ["router"]
    - path: "src/api/routes/progress.py"
      provides: "SSE progress streaming endpoint"
      exports: ["router", "sse_observer"]
    - path: "src/orchestrator/batch/sse_observer.py"
      provides: "BatchEventObserver implementation for SSE"
      exports: ["SSEProgressObserver"]
  key_links:
    - from: "src/api/routes/progress.py"
      to: "src/orchestrator/batch/sse_observer.py"
      via: "sse_observer import"
      pattern: "from src.orchestrator.batch.sse_observer import"
    - from: "src/api/routes/labels.py"
      to: "src/db/models.py"
      via: "JobRow.label_path query"
      pattern: "JobRow\\.label_path"
    - from: "src/api/main.py"
      to: "src/api/routes/commands.py"
      via: "router include"
      pattern: "include_router\\(commands\\.router"
---

<objective>
Create FastAPI backend endpoints for command submission, label downloads, and SSE progress streaming.

Purpose: Provides the API layer that the React frontend will consume for all user interactions.
Output: Complete backend API with commands, labels, and SSE endpoints ready for frontend integration.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-web-interface/07-CONTEXT.md
@.planning/phases/07-web-interface/07-RESEARCH.md
@src/api/main.py
@src/api/routes/jobs.py
@src/api/schemas.py
@src/orchestrator/batch/events.py
@src/db/models.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install backend dependencies and create SSE observer</name>
  <files>
    requirements.txt
    src/orchestrator/batch/sse_observer.py
    src/orchestrator/batch/__init__.py
  </files>
  <action>
    1. Add sse-starlette and zipstream-ng to requirements.txt

    2. Create SSEProgressObserver in src/orchestrator/batch/sse_observer.py:
       - Implements BatchEventObserver protocol
       - Maintains dict[str, asyncio.Queue] for job subscriptions
       - subscribe(job_id) -> returns asyncio.Queue for SSE events
       - unsubscribe(job_id) -> removes queue
       - All on_* methods put events to appropriate queue
       - Event format: {"event": str, "data": dict}

    3. Update src/orchestrator/batch/__init__.py to export SSEProgressObserver

    Reference 07-RESEARCH.md Pattern 1 for implementation details.
  </action>
  <verify>
    python -c "from src.orchestrator.batch import SSEProgressObserver; print('OK')"
  </verify>
  <done>
    SSEProgressObserver implements BatchEventObserver protocol and manages per-job event queues
  </done>
</task>

<task type="auto">
  <name>Task 2: Create commands and labels API routes</name>
  <files>
    src/api/routes/commands.py
    src/api/routes/labels.py
    src/api/schemas.py
  </files>
  <action>
    1. Add new schemas to src/api/schemas.py:
       - CommandSubmit: Pydantic model with command: str field
       - CommandHistoryItem: id, command, status, created_at
       - CommandSubmitResponse: job_id, status

    2. Create src/api/routes/commands.py:
       - POST /commands: Creates job with original_command, returns job_id
       - GET /commands/history: Returns last 10 commands (query jobs ordered by created_at desc)

    3. Create src/api/routes/labels.py:
       - GET /labels/{tracking_number}: Returns FileResponse for PDF from label path
       - GET /jobs/{job_id}/labels/zip: Streams ZIP of all labels for job using zipstream-ng
       - Query JobRow for label_path, check file exists, return 404 if missing

    Reference 07-RESEARCH.md code examples for ZIP streaming and command patterns.
  </action>
  <verify>
    python -c "from src.api.routes import commands, labels; print('OK')"
  </verify>
  <done>
    Commands route handles submission and history; labels route handles individual and bulk downloads
  </done>
</task>

<task type="auto">
  <name>Task 3: Create SSE progress endpoint and wire routes to main app</name>
  <files>
    src/api/routes/progress.py
    src/api/routes/__init__.py
    src/api/main.py
  </files>
  <action>
    1. Create src/api/routes/progress.py:
       - Import EventSourceResponse from sse_starlette.sse
       - Create module-level sse_observer = SSEProgressObserver()
       - GET /jobs/{job_id}/progress/stream: SSE endpoint
         - Call sse_observer.subscribe(job_id) to get queue
         - async generator yields events from queue
         - 15-second timeout yields ping event to prevent connection timeout
         - Unsubscribe on disconnect using try/finally
       - GET /jobs/{job_id}/progress: Returns current job progress (fallback for non-SSE clients)

    2. Update src/api/routes/__init__.py:
       - Export commands, labels, progress modules

    3. Update src/api/main.py:
       - Import commands, labels, progress routers
       - Include all three routers with /api/v1 prefix

    Reference 07-RESEARCH.md Pattern 1 for SSE generator pattern.
  </action>
  <verify>
    pytest tests/api/ -v --tb=short
    python -c "from src.api.main import app; print([r.path for r in app.routes if '/api/v1' in str(r.path)])"
  </verify>
  <done>
    SSE endpoint streams batch events; all new routes registered in main app
  </done>
</task>

</tasks>

<verification>
1. Run: pip install -r requirements.txt (sse-starlette and zipstream-ng installed)
2. Run: python -c "from src.api.main import app; routes = [r.path for r in app.routes]; assert '/api/v1/commands' in str(routes)"
3. Run: pytest tests/api/ -v (all existing tests pass)
4. Manual: curl -X POST http://localhost:8000/api/v1/commands -H "Content-Type: application/json" -d '{"command": "test"}' returns job_id
</verification>

<success_criteria>
- [ ] sse-starlette and zipstream-ng in requirements.txt
- [ ] SSEProgressObserver implements BatchEventObserver and manages job queues
- [ ] POST /api/v1/commands creates job and returns job_id
- [ ] GET /api/v1/commands/history returns recent commands
- [ ] GET /api/v1/labels/{tracking} returns PDF file
- [ ] GET /api/v1/jobs/{id}/labels/zip streams ZIP file
- [ ] GET /api/v1/jobs/{id}/progress/stream returns SSE stream
- [ ] All routes registered in main app
</success_criteria>

<output>
After completion, create `.planning/phases/07-web-interface/07-01-SUMMARY.md`
</output>
