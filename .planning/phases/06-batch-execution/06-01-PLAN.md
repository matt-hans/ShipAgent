---
phase: 06-batch-execution
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/mcp/data_source/tools/writeback_tools.py
  - src/mcp/data_source/server.py
  - tests/unit/mcp/data_source/test_writeback_tools.py
autonomous: true

must_haves:
  truths:
    - "Tracking numbers can be written back to CSV files"
    - "Tracking numbers can be written back to Excel files"
    - "Tracking numbers can be written back to database sources"
    - "Write-back uses atomic operations for file sources"
    - "Write-back adds tracking_number and shipped_at columns"
  artifacts:
    - path: "src/mcp/data_source/tools/writeback_tools.py"
      provides: "write_back tool implementation"
      min_lines: 150
      exports: ["write_back"]
    - path: "tests/unit/mcp/data_source/test_writeback_tools.py"
      provides: "Unit tests for write-back operations"
      min_lines: 100
  key_links:
    - from: "src/mcp/data_source/tools/writeback_tools.py"
      to: "src/mcp/data_source/server.py"
      via: "mcp.tool() registration"
      pattern: "mcp\\.tool\\(\\)\\(write_back\\)"
    - from: "src/mcp/data_source/tools/writeback_tools.py"
      to: "lifespan_context"
      via: "ctx.request_context.lifespan_context"
      pattern: "lifespan_context"
---

<objective>
Implement the write_back tool for Data Source MCP to persist tracking numbers to original data sources.

Purpose: DATA-04 requires writing tracking numbers back to the original data source after successful shipment. This tool enables the BatchExecutor to update CSV, Excel, and database sources with tracking_number and shipped_at columns.

Output: New `write_back` MCP tool registered in Data Source MCP server with atomic file operations.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-batch-execution/06-CONTEXT.md
@.planning/phases/06-batch-execution/06-RESEARCH.md

# Existing Data MCP structure
@src/mcp/data_source/server.py
@src/mcp/data_source/tools/query_tools.py
@src/mcp/data_source/models.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create write_back tool implementation</name>
  <files>src/mcp/data_source/tools/writeback_tools.py</files>
  <action>
Create a new file `src/mcp/data_source/tools/writeback_tools.py` with the `write_back` tool.

Implementation requirements:
1. Async function `write_back(row_number: int, tracking_number: str, ctx: Context, shipped_at: Optional[str] = None) -> dict`
2. Get source info from `ctx.request_context.lifespan_context["current_source"]`
3. Default `shipped_at` to current UTC time in ISO8601 format if not provided

For CSV sources (`_write_back_csv`):
- Use tempfile.mkstemp in same directory for atomic operations
- Read original with csv.DictReader
- Add tracking_number and shipped_at columns if not present
- Write to temp file, then os.replace for atomic rename
- Clean up temp file on error

For Excel sources (`_write_back_excel`):
- Use openpyxl to load workbook
- Find or create tracking_number and shipped_at columns in header row
- Excel row = row_number + 1 (accounting for header)
- Save to temp file, then os.replace for atomic rename
- Clean up temp file on error

For database sources (`_write_back_database`):
- Execute UPDATE via DuckDB attached connection
- Use parameterized query: UPDATE {table} SET tracking_number = ?, shipped_at = ? WHERE _row_number = ?
- Note: Requires _row_number column added during import (existing behavior)

Return format: `{"success": True, "source_type": str, "row_number": int, "tracking_number": str}`

Use ctx.info() for logging (never print). Handle ValueError for unsupported source types.
  </action>
  <verify>
Run `python -c "from src.mcp.data_source.tools.writeback_tools import write_back; print('Import OK')"`
  </verify>
  <done>
write_back function exists with implementations for CSV, Excel, and database sources. Uses atomic file operations (temp + rename) for file sources.
  </done>
</task>

<task type="auto">
  <name>Task 2: Register write_back tool in Data MCP server</name>
  <files>src/mcp/data_source/server.py</files>
  <action>
Update `src/mcp/data_source/server.py` to register the new write_back tool.

1. Add import at the end of the imports section:
```python
from src.mcp.data_source.tools.writeback_tools import write_back
```

2. Add tool registration after the existing registrations:
```python
mcp.tool()(write_back)
```

Follow the existing pattern used for other tools in the file.
  </action>
  <verify>
Run `python -c "from src.mcp.data_source.server import mcp; tools = [t.name for t in mcp._tools.values()]; print('write_back' in tools)"`
  </verify>
  <done>
write_back tool is registered in Data MCP server and discoverable via MCP tool listing.
  </done>
</task>

<task type="auto">
  <name>Task 3: Create unit tests for write_back tool</name>
  <files>tests/unit/mcp/data_source/test_writeback_tools.py</files>
  <action>
Create comprehensive unit tests for the write_back tool.

Test categories:

1. CSV write-back tests:
   - test_write_back_csv_adds_columns: New columns added when missing
   - test_write_back_csv_updates_existing: Updates existing tracking_number column
   - test_write_back_csv_atomic_on_error: Temp file cleaned up on error
   - test_write_back_csv_preserves_data: Other columns unchanged

2. Excel write-back tests:
   - test_write_back_excel_adds_columns: New columns added to header
   - test_write_back_excel_updates_existing: Updates existing values
   - test_write_back_excel_correct_row: Row number maps correctly (data row + 1)
   - test_write_back_excel_sheet_selection: Works with named sheets

3. Database write-back tests:
   - test_write_back_database_updates_row: UPDATE executes correctly
   - test_write_back_database_parameterized: Uses parameterized queries (no injection)

4. Error handling tests:
   - test_write_back_no_source_loaded: ValueError when no current_source
   - test_write_back_unsupported_type: ValueError for unknown source types
   - test_write_back_row_not_found: Appropriate error for missing row

Use pytest fixtures to create temp CSV/Excel files. Mock DuckDB connection for database tests.
Use AsyncMock for ctx parameter with lifespan_context configured.
  </action>
  <verify>
Run `pytest tests/unit/mcp/data_source/test_writeback_tools.py -v`
  </verify>
  <done>
All unit tests pass. Tests cover CSV, Excel, and database write-back with atomic operations and error handling.
  </done>
</task>

</tasks>

<verification>
- [ ] write_back tool imported successfully from writeback_tools module
- [ ] write_back registered in Data MCP server tools list
- [ ] All unit tests pass with `pytest tests/unit/mcp/data_source/test_writeback_tools.py -v`
- [ ] CSV write-back uses atomic temp-then-rename pattern
- [ ] Excel write-back uses atomic temp-then-rename pattern
- [ ] Database write-back uses parameterized queries
</verification>

<success_criteria>
- write_back tool is registered and callable via MCP
- Supports all three source types: CSV, Excel, database
- File operations are atomic (no data corruption on crash)
- Unit tests provide >90% coverage of write-back logic
</success_criteria>

<output>
After completion, create `.planning/phases/06-batch-execution/06-01-SUMMARY.md`
</output>
