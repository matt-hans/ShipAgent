---
phase: 01-foundation
plan: 02
type: execute
wave: 2
depends_on: ["01-01"]
files_modified:
  - src/services/__init__.py
  - src/services/job_service.py
autonomous: true

must_haves:
  truths:
    - "Jobs can be created with name, description, and original command"
    - "Job state can only transition through valid paths (pending->running->completed)"
    - "Per-row status can be tracked and updated"
    - "Failed jobs preserve which rows succeeded vs failed"
  artifacts:
    - path: "src/services/job_service.py"
      provides: "Job CRUD and state machine operations"
      exports: ["JobService", "InvalidStateTransition"]
    - path: "src/services/__init__.py"
      provides: "Service layer exports"
      exports: ["JobService"]
  key_links:
    - from: "src/services/job_service.py"
      to: "src/db/models.py"
      via: "imports Job, JobRow, JobStatus, RowStatus"
      pattern: "from src.db.*import.*Job"
    - from: "src/services/job_service.py"
      to: "src/db/connection.py"
      via: "uses Session for database operations"
      pattern: "Session"
---

<objective>
Create the Job Service implementing job lifecycle management with state machine validation and per-row tracking.

Purpose: Provide the core business logic layer for job operations that enforces valid state transitions and supports crash recovery through per-row status.

Output: JobService class with CRUD operations, state machine validation, and row-level tracking.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/01-foundation/01-CONTEXT.md
@src/db/models.py
@src/db/connection.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create JobService with CRUD operations</name>
  <files>
    - src/services/__init__.py
    - src/services/job_service.py
  </files>
  <action>
Create the job service with CRUD operations and state machine logic.

**src/services/__init__.py**:
```python
from src.services.job_service import JobService, InvalidStateTransition

__all__ = ["JobService", "InvalidStateTransition"]
```

**src/services/job_service.py**:

1. **Exception classes**:
   - `InvalidStateTransition(Exception)`: Raised when attempting invalid state change
     - Include: current_state, attempted_state, allowed_transitions

2. **State transition map** (from CONTEXT.md):
   ```python
   VALID_TRANSITIONS = {
       JobStatus.pending: [JobStatus.running],
       JobStatus.running: [JobStatus.paused, JobStatus.completed, JobStatus.failed, JobStatus.cancelled],
       JobStatus.paused: [JobStatus.running, JobStatus.cancelled],
       JobStatus.completed: [],  # terminal
       JobStatus.failed: [],  # terminal (retry creates new job with same rows)
       JobStatus.cancelled: [],  # terminal
   }
   ```

3. **JobService class**:

   Constructor:
   - `__init__(self, db: Session)`: Accept SQLAlchemy session

   CRUD methods:
   - `create_job(name: str, original_command: str, description: str | None = None, mode: str = "confirm") -> Job`:
     - Generate UUID for id
     - Set status to pending
     - Set timestamps (created_at, updated_at)
     - Add to session, commit, refresh
     - Return created job

   - `get_job(job_id: str) -> Job | None`:
     - Query by id
     - Return None if not found

   - `list_jobs(status: JobStatus | None = None, limit: int = 50, offset: int = 0) -> list[Job]`:
     - Filter by status if provided
     - Order by created_at DESC (most recent first)
     - Apply limit and offset
     - Return list of jobs

   - `delete_job(job_id: str) -> bool`:
     - Delete job (cascade deletes rows and logs)
     - Return True if deleted, False if not found

   State machine methods:
   - `update_status(job_id: str, new_status: JobStatus) -> Job`:
     - Get current job
     - Validate transition is allowed using VALID_TRANSITIONS
     - If invalid, raise InvalidStateTransition with details
     - Update status and updated_at timestamp
     - If new_status is completed/failed/cancelled, set completed_at
     - If new_status is running and started_at is None, set started_at
     - Commit and return updated job

   - `can_transition(current: JobStatus, target: JobStatus) -> bool`:
     - Return True if transition is valid

   Job metrics methods:
   - `update_counts(job_id: str, total: int | None = None, processed: int | None = None, successful: int | None = None, failed: int | None = None) -> Job`:
     - Update whichever counts are provided
     - Update updated_at
     - Commit and return

   - `set_error(job_id: str, error_code: str, error_message: str) -> Job`:
     - Set error_code and error_message on job
     - Commit and return

Use type hints throughout. Use `from datetime import datetime, UTC` for timestamps.
  </action>
  <verify>
    - `python -c "from src.services import JobService, InvalidStateTransition"` succeeds
    - `python -c "from src.services.job_service import VALID_TRANSITIONS; print(VALID_TRANSITIONS)"` shows state map
  </verify>
  <done>
    - JobService class implemented with all CRUD methods
    - State machine validates transitions
    - InvalidStateTransition exception raised for invalid transitions
    - Counts and error fields can be updated
  </done>
</task>

<task type="auto">
  <name>Task 2: Add per-row tracking methods to JobService</name>
  <files>
    - src/services/job_service.py
  </files>
  <action>
Extend JobService with per-row tracking methods for crash recovery and retry capability.

Add these methods to JobService class:

Row CRUD:
- `create_rows(job_id: str, row_data: list[dict]) -> list[JobRow]`:
  - Each dict has: row_number (int), row_checksum (str)
  - Create JobRow for each with status=pending
  - Bulk insert for efficiency
  - Update job.total_rows count
  - Return created rows

- `get_row(row_id: str) -> JobRow | None`:
  - Simple query by id

- `get_rows(job_id: str, status: RowStatus | None = None) -> list[JobRow]`:
  - Get all rows for job, optionally filtered by status
  - Order by row_number ASC

- `get_pending_rows(job_id: str) -> list[JobRow]`:
  - Convenience method: get_rows with status=pending

- `get_failed_rows(job_id: str) -> list[JobRow]`:
  - Convenience method: get_rows with status=failed

Row state updates:
- `start_row(row_id: str) -> JobRow`:
  - Set status to processing
  - Return updated row

- `complete_row(row_id: str, tracking_number: str, label_path: str, cost_cents: int) -> JobRow`:
  - Set status to completed
  - Set tracking_number, label_path, cost_cents
  - Set processed_at timestamp
  - Update job.processed_rows and job.successful_rows counts
  - Return updated row

- `fail_row(row_id: str, error_code: str, error_message: str) -> JobRow`:
  - Set status to failed
  - Set error_code and error_message
  - Set processed_at timestamp
  - Update job.processed_rows and job.failed_rows counts
  - Return updated row

- `skip_row(row_id: str) -> JobRow`:
  - Set status to skipped (for retry scenarios)
  - Return updated row

Aggregation:
- `get_job_summary(job_id: str) -> dict`:
  - Return dict with:
    - total_rows, processed_rows, successful_rows, failed_rows
    - pending_count (calculated)
    - total_cost_cents (sum of successful rows)
    - status, created_at, started_at, completed_at
  </action>
  <verify>
    - Run integration test (see verification section)
  </verify>
  <done>
    - Row CRUD methods work
    - Row state transitions work
    - Job counts auto-update when rows complete/fail
    - get_job_summary returns accurate aggregation
  </done>
</task>

</tasks>

<verification>
After all tasks complete, run this integration test:

```bash
python -c "
from src.db.connection import init_db, get_db
from src.db.models import JobStatus, RowStatus
from src.services import JobService, InvalidStateTransition

# Setup
init_db()
db = next(get_db())
svc = JobService(db)

# Test job creation
job = svc.create_job(
    name='Test Batch',
    original_command='Ship California orders via Ground',
    description='Testing state machine'
)
print(f'1. Created job: {job.id}, status: {job.status.value}')
assert job.status == JobStatus.pending

# Test valid transition: pending -> running
job = svc.update_status(job.id, JobStatus.running)
print(f'2. Transitioned to: {job.status.value}')
assert job.status == JobStatus.running
assert job.started_at is not None

# Test invalid transition: running -> pending
try:
    svc.update_status(job.id, JobStatus.pending)
    print('3. ERROR: Should have raised InvalidStateTransition')
except InvalidStateTransition as e:
    print(f'3. Correctly rejected invalid transition: {e}')

# Test row creation
rows = svc.create_rows(job.id, [
    {'row_number': 1, 'row_checksum': 'abc123'},
    {'row_number': 2, 'row_checksum': 'def456'},
    {'row_number': 3, 'row_checksum': 'ghi789'},
])
print(f'4. Created {len(rows)} rows, job.total_rows: {job.total_rows}')
assert len(rows) == 3

# Test row processing
row1 = svc.start_row(rows[0].id)
assert row1.status == RowStatus.processing
print(f'5. Row 1 started: {row1.status.value}')

row1 = svc.complete_row(rows[0].id, 'TRACK001', '/labels/track001.pdf', 1250)
print(f'6. Row 1 completed: tracking={row1.tracking_number}, cost={row1.cost_cents}')

row2 = svc.start_row(rows[1].id)
row2 = svc.fail_row(rows[1].id, 'E-2001', 'Invalid ZIP code')
print(f'7. Row 2 failed: {row2.error_code} - {row2.error_message}')

# Test summary
summary = svc.get_job_summary(job.id)
print(f'8. Summary: processed={summary[\"processed_rows\"]}, success={summary[\"successful_rows\"]}, failed={summary[\"failed_rows\"]}')
assert summary['successful_rows'] == 1
assert summary['failed_rows'] == 1

# Test failed rows query
failed = svc.get_failed_rows(job.id)
print(f'9. Failed rows: {[r.row_number for r in failed]}')
assert len(failed) == 1

# Cleanup
svc.delete_job(job.id)
print('10. Job deleted')

db.close()
print('\\nAll tests passed!')
"

# Cleanup test database
rm -f shipagent.db
```
</verification>

<success_criteria>
1. Jobs can be created with all required fields
2. State transitions validate against the state machine map
3. Invalid transitions raise InvalidStateTransition with details
4. Rows can be created, tracked, and updated per-row
5. Job counts auto-update when rows are processed
6. get_job_summary returns accurate metrics
7. Failed rows can be queried for retry scenarios
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation/01-02-SUMMARY.md`
</output>
